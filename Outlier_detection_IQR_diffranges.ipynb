{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection - Normalizing by volume for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muthulakshmi C\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Import the libraries needed\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import csv\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iqr_dict(p,q1,q3,unique_roi):\n",
    "    #Make a copy of the panel. \n",
    "    #Find IQR of each column for the specified quartiles. \n",
    "    #Check if each entry is in the IQR - output False if no outlier, True if it is an outlier. \n",
    "    p_new = p\n",
    "    dict_iqr = {}\n",
    "    iqr_dict = {}\n",
    "    panel_actualval = pd.Panel()\n",
    "    for i in range(len(unique_roi)) :\n",
    "        each_roi = unique_roi[i]\n",
    "        df = p_new[each_roi]\n",
    "        Q1 = df.quantile(q1)\n",
    "        Q3 = df.quantile(q3)\n",
    "        IQR = Q3 - Q1\n",
    "        df_new = (df < (Q1 - 1.5 * IQR))|(df > (Q3 + 1.5 * IQR))\n",
    "        y = list(df_new[df_new == True].stack().index) \n",
    "        for element in y:\n",
    "            val = df.loc[element[0],str(element[1])]\n",
    "            df_new.loc[element[0],str(element[1])] = val\n",
    "        p_new[each_roi] = df_new\n",
    "\n",
    "        iqr_df = pd.DataFrame(df_new.columns)\n",
    "        iqr_df = iqr_df.append(Q1)\n",
    "        iqr_df = iqr_df.append(Q3)\n",
    "        dict_iqr[each_roi] = iqr_df\n",
    "        iqr_dict[each_roi] = [Q1,Q3]\n",
    "        panel_iqr = pd.Panel(dict_iqr)\n",
    "    return panel_iqr,iqr_dict      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roi_dict():\n",
    "    #Create a dictionary of ROI_IDs and their names from the .xml file\n",
    "    roi_dict={}\n",
    "    current_path = os.getcwd()\n",
    "    xml_file = os.path.join(os.getcwd(),'labels.xml')\n",
    "    root = et.parse(xml_file).getroot()\n",
    "#     print('Root :',root)\n",
    "    for roi in root.findall('label'):\n",
    "        att = roi.attrib\n",
    "        roi_id = int(att.get('id'))\n",
    "        roi_name = att.get('fullname')\n",
    "        roi_dict[roi_id] = roi_name\n",
    "\n",
    "#     print('Attributes:',att)\n",
    "#     print('ROI_ID:',roi_id)\n",
    "#     print('ROI_Name:',roi_name)\n",
    "    return roi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testdf(testfile):\n",
    "    test_file = pd.read_csv(testfile,delimiter='\\t')\n",
    "    test_df = test_file[test_file['ROI_ID']!=900] #removing cerebellum\n",
    "    test_df.drop(columns='CSF_Volume(mm^3)',inplace=True) #removing CSF_Volume\n",
    "            #Normalizing by volume per subject across all rois\n",
    "    tot_vol1 = test_df['Total_Volume(GM+WM)(mm^3)'].sum()\n",
    "    #     print(tot_vol)\n",
    "    for item in test_df.columns:\n",
    "        if(item!='ROI_ID'):\n",
    "            test_df.loc[:,str(item)] /= tot_vol1\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(output_file,df):\n",
    "    df.to_csv(output_file, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_outliers(panel_iqr,test_df,quart1,quart3,common_roi,iqr_dict):\n",
    "    outlier_roi=[]\n",
    "#     output_file = 'output_iqr_116_S_6517_T1w_edited.txt'\n",
    "#     with open(output_file,'w') as file:\n",
    "#     #         print('File:',allFiles_new[i])\n",
    "    c=0\n",
    "    outlier_df = pd.DataFrame(columns=['LowerBound','UpperBound','ROI_ID','ROI_Name','Measure','Value','InlierBound1','InlierBound2'])\n",
    "    roi_dict = create_roi_dict()\n",
    "    for every_roi in common_roi :\n",
    "        all_stat = test_df[test_df['ROI_ID'] == every_roi]\n",
    "        roi_stat = all_stat.drop('ROI_ID',axis = 1, inplace=False)\n",
    "        iqr_info = iqr_dict[every_roi]\n",
    "        q1 = iqr_dict[every_roi][0]\n",
    "        q3 = iqr_dict[every_roi][1]\n",
    "        iqr = q3 - q1\n",
    "        temp =(roi_stat < (q1 - 1.5 * iqr))|(roi_stat > (q3 + 1.5 * iqr)) \n",
    "        temp2 = pd.DataFrame(data = temp)\n",
    "        s = temp2.stack()\n",
    "        outlier_regions = s[s].index.tolist()\n",
    "        if(len(outlier_regions)!=0):\n",
    "            outlier_roi.append(every_roi)\n",
    "            for item in outlier_regions :\n",
    "                roi_id = every_roi\n",
    "                roi_name = roi_dict[roi_id]\n",
    "                measure = item[1]\n",
    "                val = all_stat.loc[item[0],str(item[1])]\n",
    "#                     print(q1.type)\n",
    "                bound1 = panel_iqr[roi_id].loc[float(quart1),str(measure)]\n",
    "                bound2 = panel_iqr[roi_id].loc[float(quart3),str(measure)]\n",
    "                outlier_row=[quart1,quart3,roi_id,roi_name,measure,val,bound1,bound2]\n",
    "                outlier_df = outlier_df.append(pd.Series(dict(zip(outlier_df.columns,outlier_row))), ignore_index=True)\n",
    "#                 print(roi_id,\"-\",roi_name,\"-\",measure,\"-\",val,\"-\",bound1,\"-\",bound2)\n",
    "#                 file.write('['+str(quart1)+','+str(quart3)+']\\t'+str(roi_id)+'\\t'+str(roi_name)+'\\t'+str(measure)+'\\t'+str(val)+'\\t[ '+str(bound1)+' - '+str(bound2)+' ]\\n')\n",
    "    return outlier_df,outlier_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths of input and output files\n",
    "#path - the path of input file \n",
    "#path_iqr - path of output file\n",
    "current_dir = os.getcwd()\n",
    "path = os.path.join(current_dir,'cnstats')\n",
    "path_iqr = os.path.join(current_dir,'cnstats_iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output file directory \n",
    "#Removing all files already in the directory\n",
    "opdir_avl_files = glob.glob(path_iqr+\"/*.txt\")\n",
    "for f in opdir_avl_files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob(path + \"/*.txt\")\n",
    "\n",
    "#Reading each file as a dataframe, and storing it in a list\n",
    "fileslist = []\n",
    "frame = pd.DataFrame()\n",
    "for i in range(len(allFiles)):\n",
    "    file = allFiles[i]\n",
    "    df = pd.read_csv(file,index_col=None, header=0,delimiter='\\t')\n",
    "    df = df[df['ROI_ID']!=900] #removing cerebellum\n",
    "    df.drop(columns='CSF_Volume(mm^3)',inplace=True) #removing CSF_Volume\n",
    "    #Normalizing by volume per subject across all rois\n",
    "    tot_vol = df['Total_Volume(GM+WM)(mm^3)'].sum()\n",
    "    for item in df.columns:\n",
    "        if(item!='ROI_ID'):\n",
    "            df.loc[:,str(item)] /= tot_vol\n",
    "    fileslist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the list into a vertical stack, and find the column headers\n",
    "data_2d_array = np.vstack(fileslist)\n",
    "data_vstack = pd.DataFrame(data_2d_array)\n",
    "# print(data_vstack.shape)\n",
    "data_vstack.columns = df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the unique ROI_IDs and store it \n",
    "unique_roi = data_vstack.ROI_ID.unique()\n",
    "unique_roi = [int(i) for i in unique_roi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D dataframe to be implemented using Panels. Hence reordering the index.\n",
    "#Data is grouped by ROI_ID. Dict keys are ROI_IDs.\n",
    "temp_df = pd.DataFrame()\n",
    "temp_dict = {}\n",
    "for i in range(len(unique_roi)):\n",
    "    each_roi = unique_roi[i]\n",
    "    temp_df = data_vstack[data_vstack['ROI_ID'] == each_roi]\n",
    "    index_range = range(temp_df.shape[0])\n",
    "    temp_df['new_ind'] = index_range\n",
    "    temp_df.set_index('new_ind',inplace=True)\n",
    "    temp_dict[each_roi] = temp_df\n",
    "#     print(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a panel from the dictionary\n",
    "p = pd.Panel(temp_dict)\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf = '116_S_6517_T1w_edited.roiwise.stats.txt'\n",
    "test_df = create_testdf(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_roi_test = list(test_df['ROI_ID'])\n",
    "# print(unique_roi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_roi = list(set(unique_roi).intersection(unique_roi_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panel_iqr = pd.Panel(dict_iqr)\n",
    "iqr_limits = [[0.1,0.9]]\n",
    "outlier_df = pd.DataFrame()\n",
    "outlier_roi = []\n",
    "#Create IQR dictionary\n",
    "for i in range(len(iqr_limits)):\n",
    "    i1 = iqr_limits[i]\n",
    "    limit1 = i1[0]\n",
    "    limit2 = i1[1]\n",
    "#     print(\"Limits:\",limit1,\"-\",limit2)\n",
    "    p = pd.Panel(temp_dict)\n",
    "    panel_iqr,iqr_dict = create_iqr_dict(p,limit1,limit2,unique_roi)\n",
    "    g,roi = test_outliers(panel_iqr,test_df,limit1,limit2,common_roi,iqr_dict)\n",
    "    outlier_roi.append(roi)\n",
    "    outlier_df = outlier_df.append(g,ignore_index=True)\n",
    "#     outf = 'output_iqr_116_S_6517_T1w_edited.txt'\n",
    "#     print(g)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to output file \n",
    "output_file = 'output_iqr_116_S_6517_T1w_edited.csv'\n",
    "write_to_file(output_file,outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the actual image, and then the outlier image\n",
    "path = os.path.join(current_dir,'116_S_6517_T1w_edited.svreg.label.nii.gz')\n",
    "labeldata = image.load_img(path)\n",
    "# print(labeldata.shape)\n",
    "# plotting.plot_stat_map(labeldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = labeldata.get_data()\n",
    "x,y,z = np.shape(ld)\n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        for k in range(z):\n",
    "            if ld[i,j,k]>1000:\n",
    "                ld[i,j,k]=ld[i,j,k]%1000\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda = labeldata.get_data()\n",
    "arr = np.zeros(shape=np.shape(ld))\n",
    "for i in range(len(outlier_roi)):\n",
    "    if i==0:\n",
    "        new_elem = outlier_roi[i]\n",
    "    else:\n",
    "        list1 = outlier_roi[i-1]\n",
    "        list2 = outlier_roi[i]\n",
    "        new_elem = list(np.setdiff1d(list2,list1))\n",
    "#     print('------------')\n",
    "#     print('New elem:',new_elem)\n",
    "    lda = np.isin(ld, new_elem)\n",
    "#     print(\"Iter:\",i,\" before :\",np.count_nonzero(arr))    \n",
    "    arr += lda.astype(int) * (80*(i+1))\n",
    "#     print(\"Iter:\",i,\" aft :\",np.count_nonzero(arr))\n",
    "#     print(np.isclose(arr,80*(i+1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lda = image.new_img_like(labeldata, arr, affine=None, copy_header=True)\n",
    "# plotting.plot_stat_map(new_lda,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lda.to_filename('output_iqr_116_S_6517_T1w_edited.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
